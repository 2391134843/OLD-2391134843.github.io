---
title: kafka的介绍和安装以及实例讲解
date: 2018-6-10 10:30:10
categories:
- 大数据,kafka
# comments: true
---
# kafka简介以及在Ubuntu环境下kafka的安装和实例介绍
## kafka的介绍：
### kafka是什么？有什么用？
Kafka 是一种搞吞吐量的分布式发布订阅消息系统，他可以处理消费着规模的网站中的动作流数据。
Kafka的目的是通过Hadoop和Spark 等的并行加载机制来统一线上和离线的消息处理。
### kafka的相关概念
+ Broker ：Kafka集群包含一个或多个服务器，这些服务器称为Broker
+ Topic : 每条发布到Kafka集群的消息都有一个类别，这个类别称之为Topic,物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存在一个或多个Broker上，但是用户只需要指定消息的Topic,即可生产或者消费数据，而不必关心数据存于何处
+ Partition :是物理上的概念，每个Topic包含一个或多个Partition
+ Producer: 负责发布消息到Kafka Broker
+ Consumer: 消息消费之，想Kafka Broker 读取消息的客户端
+ Consumer Group: 每个Consumer属于一个特定的Consumer Group，可以为每个Consumer指定group name , 若不指定则属于默认的group


## 安装kafka
### Kafka安装包的下载

+ 1.访问[Kafka官网](https://kafka.apache.org/downloads)下载页面,下载Kafka稳定版的安装包kafka_2.10-0.10.1.0.tgz,
+ 2.或者访问我以及准备好的github链接直接下载稳定版安装包[下载地址](https://github.com/2391134843/BigData/tree/master/Kafka)
__两种安装方式都很方便，请大家自己选择推荐第二种__

### kafka安装操作
__文件下载之后需要解压，按照Linux的系统的规范，一般用户安装的软件都是存放在/usr/local 目录下面__
__具体步骤如下：__

> ～ cd ~/下载

> ～ sudo tar -zxf kafka_2.10-0.10.1.0.tgz -C /usr/local

>～ cd /usr/local

>～ sudo mv kafka_2.10-0.10.1.0.tgz/ ./kafka

>～ sudo chown 777 ./kafka

__(注意这里可能有人会问有些教程不是用 sudo chown -R hadoop ./kafka 吗？
我之前也是用这个权限命令，但是这样会报错，有些文件的创建权限不够，如下图：)__
![](http://p8i28834i.bkt.clouddn.com/kafuka-1.png)

## 实例介绍
### 第一个终端
新建立一个Linux终端，执行如下命令启动Zookeeper:

>～ cd /usr/local/kafka

>～ bin/zookeeper-server-start.sh config/zookeeper.properties

执行结果：
![](http://p8i28834i.bkt.clouddn.com/kafuka-%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%BB%88%E7%AB%AF.png)

__注意！！！ 执行了上面的命令之后会弹出一大堆信息，有两种情况，一种是刚刚在上面说了的那种权限不够的问题，还有一种是成功了，两种都会弹出一大堆信息，并且停住不动，没有回到shell命令提示符状态，这是正常的不要误以为死机，如果此时你讲这个终端关闭了则Zookeeper服务就停止了__


### 第二个终端
> ~ cd /usr/local/kafka

>~ ./bin/kafka-server-start.sh config/server.properties

执行结果：
![](http://p8i28834i.bkt.clouddn.com/kafuka-%E7%AC%AC%E4%BA%8C%E4%B8%AA%E7%BB%88%E7%AB%AF.png)

### 第三个个终端
同样的，我们需要重新在建立一个新的终端，不会同时建立多个终端的朋友请自行百度，Google
> ~ cd /usr/local/kafka

>~ ./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic dblab

执行结果：
![](http://p8i28834i.bkt.clouddn.com/kafuka-%E7%AC%AC%E4%B8%89%E4%B8%AA%E7%BB%88%E7%AB%AF.png)

__我之前已经创建过了，所以显示以及存在，如果没有创建过则会显示Created topic XXX__


__topic 是用来发布消息的category,一单节点的配置方式创建一个名为dblab的topic。可以利用list命令列出所有创建了的topics,来产看刚才创建的topic是否存在，命令如下：__
>~ cd /usr/local/kafka

>~ ./bin/kafka-topics.sh --list --zookeeper localhost:2181

在已经知道创建了topic之后可以来用producer生产一些数据：
> ~ cd /usr/local/kafka

>~ ./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic dblab

在该命令之心后，可以在终端中输入以下信息来测试
hello hadoop
hello haha
hadoop world

### 打开第四个终端：
使用consumer来接受刚刚写入的数据
> ~ cd /usr/local/kafka

>～ ./bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic dblab --from-beginning

执行结果：
![](http://p8i28834i.bkt.clouddn.com/kafuka-%E7%AC%AC%E5%9B%9B%E4%B8%AA%E7%BB%88%E7%AB%AF.png)
当显示出你输入的信息之后则说明kafuka安装完全成功
## 最终我们应该有四个中断：
![](http://p8i28834i.bkt.clouddn.com/kafuka-%E5%85%A8%E5%9B%9B%E4%B8%AA%E7%BB%88%E7%AB%AF.png)


